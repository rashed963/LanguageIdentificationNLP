{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN77ZJnWUcIMO2y1q8/qkpN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rashed963/LanguageIdentificationNLP/blob/main/notebooks/LR_Ngram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Approach 1: character-level n-gram representation and Logistic Regression\n",
        "\n",
        "In this notebook, we developed a language identification model using a character-level uni/bi-gram representation and Logistic Regression. This approach is effective for distinguishing between different languages due to the unique character patterns and sequences found in languages.\n",
        "\n",
        "We utilized a relatively simple yet powerful machine learning pipeline consisting of a CountVectorizer for feature extraction and LogisticRegression for classification. This combination is not only computationally efficient but also performs well on textual data that varies in linguistic structure.\n",
        "\n",
        "The model was trained and evaluated on a sampled subset of a larger dataset to expedite the computation process, particularly suitable for environments like Google Colab with limited computational resources."
      ],
      "metadata": {
        "id": "TJJa2fCEDjWa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X3unvBFWYCVH"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from joblib import dump, load\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #Mount Google Drive to access the dataset directly from Google Drive storage."
      ],
      "metadata": {
        "id": "lOYSstFmYX9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "zPjEFdYOFjHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "#unsed for now\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess the input text for language identification.\n",
        "\n",
        "    Args:\n",
        "    text (str): The input text to preprocess.\n",
        "\n",
        "    Returns:\n",
        "    str: The preprocessed text.\n",
        "    \"\"\"\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)  # Keep lowercased letters and spaces\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "8oIf6lVJFr-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Sampling\n",
        "\n",
        "This section covers the loading and random sampling of the training and testing data. Sampling is particularly useful to reduce computation time while developing the model on Google Colab. We use a sample size of 25,000 for training and 10,000 for testing to ensure a representative subset of the full dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "NaEnJB9VBxW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_sample(filepath, sample_size=10, random_state=42):\n",
        "    \"\"\"\n",
        "    Load a random sample of lines from a file to reduce memory usage and speed up computations.\n",
        "    \"\"\"\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "      lines = file.readlines()\n",
        "\n",
        "    random.seed(random_state)\n",
        "    sampled_indices = random.sample(range(len(lines)), sample_size)\n",
        "    sampled_lines = [lines[i].strip() for i in sampled_indices]\n",
        "    return sampled_lines\n",
        "\n",
        "def load_datasets(train_data_path, train_labels_path, test_data_path, test_labels_path, train_sample_size=25000, test_sample_size=10000):\n",
        "    \"\"\"\n",
        "    Load training and testing data and labels from specified file paths.\n",
        "\n",
        "    Args:\n",
        "    train_data_path (str): Path to the training data file.\n",
        "    train_labels_path (str): Path to the training labels file.\n",
        "    test_data_path (str): Path to the testing data file.\n",
        "    test_labels_path (str): Path to the testing labels file.\n",
        "    train_sample_size (int): Number of samples to load from the training data.\n",
        "    test_sample_size (int): Number of samples to load from the testing data.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Tuple containing loaded training data, training labels, testing data, testing labels.\n",
        "    \"\"\"\n",
        "    # Load training data and labels\n",
        "    X_train = load_data_sample(train_data_path, sample_size=train_sample_size)\n",
        "    y_train = load_data_sample(train_labels_path, sample_size=train_sample_size)\n",
        "\n",
        "    # Load testing data and labels\n",
        "    X_test = load_data_sample(test_data_path, sample_size=test_sample_size)\n",
        "    y_test = load_data_sample(test_labels_path, sample_size=test_sample_size)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\n",
        "# Define the base path for data files\n",
        "base_path = '/content/drive/MyDrive/data'\n",
        "\n",
        "# Paths to data files using the base path\n",
        "train_data_path = f'{base_path}/train/x_train.txt'\n",
        "train_labels_path = f'{base_path}/train/y_train.txt'\n",
        "test_data_path = f'{base_path}/test/x_test.txt'\n",
        "test_labels_path = f'{base_path}/test/y_test.txt'"
      ],
      "metadata": {
        "id": "emHYpZ08YbMh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training & Model Evaluation\n",
        "\n",
        "- We employ a character-level bi-gram model combined with a Logistic Regression classifier. This approach is often effective for language identification tasks, where character n-grams serve as strong features for distinguishing between languages (Reference: []).\n",
        "\n",
        "- After training, the model's performance is evaluated on the test set to ensure its effectiveness. Accuracy is the metric of choice for its interpretability and relevance in classification tasks."
      ],
      "metadata": {
        "id": "hi2eJj12B-TH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Train a logistic regression model on character-level uni/bi-gram features.\n",
        "    \"\"\"\n",
        "    model = make_pipeline(CountVectorizer(analyzer='char', ngram_range=(1, 2)), LogisticRegression(max_iter=500))\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "def predict_language(text, model):\n",
        "    return model.predict([text])[0]"
      ],
      "metadata": {
        "id": "Z8DdYuR_CH06"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all datasets using simplified paths\n",
        "X_train, y_train, X_test, y_test = load_datasets(train_data_path, train_labels_path, test_data_path, test_labels_path)"
      ],
      "metadata": {
        "id": "26uFMFMeYe9Y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**V1. Logistic Regression**"
      ],
      "metadata": {
        "id": "dVeBpe9YYmQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model = train_model(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = [predict_language(text, model) for text in X_test]\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "#model_v0.1:  ngram_range=(1, 1): iter = 50: Accuracy: 0.8085\n",
        "#model_v0.2:  ngram_range=(1, 1): iter = 500: Accuracy: 0.8513"
      ],
      "metadata": {
        "id": "tgpEXBO1YiGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dump(model, 'lr_tfidf_1gram_v0.2.joblib')\n",
        "files.download('lr_tfidf_1gram_v0.2.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "FXbm84DgKPv5",
        "outputId": "a729fa7a-184a-4ca6-d75e-563ea7472584"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ef23d475-a1f4-45da-a6e2-621b5d8469f6\", \"lr_tfidf_1gram_v0.2.joblib\", 14544765)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}